{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "if __name__ == '__main__':\n",
    "    import os\n",
    "    # Change the current working directory to the parent directory of this file\n",
    "    os.chdir(os.path.dirname(os.path.dirname(os.path.dirname(__vsc_ipynb_file__))))\n",
    "\n",
    "from evaluation import get_actual_demand\n",
    "from system_state import SystemState\n",
    "from utils import load_problem_data\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import uuid\n",
    "import json\n",
    "\n",
    "demand, datacenters, servers, selling_prices = load_problem_data()\n",
    "system_state = SystemState(datacenters, servers)\n",
    "\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "actual_demand = get_actual_demand(demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server generation: GPU.S3, Latency sensitivity: high\n",
      "Total servers bought: 484\n",
      "Server generation: GPU.S3, Latency sensitivity: medium\n",
      "Total servers bought: 758\n",
      "Server generation: GPU.S3, Latency sensitivity: low\n",
      "Total servers bought: 791\n",
      "Server generation: GPU.S2, Latency sensitivity: high\n",
      "Total servers bought: 849\n",
      "Server generation: GPU.S1, Latency sensitivity: high\n",
      "Total servers bought: 1643\n",
      "Server generation: GPU.S2, Latency sensitivity: medium\n",
      "Total servers bought: 1770\n",
      "Server generation: GPU.S1, Latency sensitivity: medium\n",
      "Total servers bought: 1904\n",
      "Server generation: GPU.S2, Latency sensitivity: low\n",
      "Total servers bought: 2001\n",
      "Server generation: GPU.S1, Latency sensitivity: low\n",
      "Total servers bought: 2171\n",
      "Server generation: CPU.S4, Latency sensitivity: high\n",
      "Total servers bought: 3433\n",
      "Server generation: CPU.S3, Latency sensitivity: high\n",
      "Total servers bought: 4081\n",
      "Server generation: CPU.S4, Latency sensitivity: medium\n",
      "Total servers bought: 6826\n",
      "Server generation: CPU.S3, Latency sensitivity: medium\n",
      "Total servers bought: 8465\n",
      "Server generation: CPU.S2, Latency sensitivity: high\n",
      "Total servers bought: 10110\n",
      "Server generation: CPU.S4, Latency sensitivity: low\n",
      "Total servers bought: 13249\n",
      "Server generation: CPU.S3, Latency sensitivity: low\n",
      "Total servers bought: 14863\n",
      "Server generation: CPU.S2, Latency sensitivity: medium\n",
      "Total servers bought: 16118\n",
      "Server generation: CPU.S2, Latency sensitivity: low\n",
      "Total servers bought: 16680\n"
     ]
    }
   ],
   "source": [
    "# Simulate the algorithm with the most profitable server/latency\n",
    "from greedy_profit_v2.data import get_sorted_servers, break_even_time_all\n",
    "from greedy_profit_v2.results import save_results_as_actions\n",
    "\n",
    "\n",
    "results = []\n",
    "sorted_servers = get_sorted_servers('data/test_data/most_profitable_servers_by_artem.csv')\n",
    "\n",
    "for server_generation, latency_sensitivity in sorted_servers:\n",
    "    remaining_demand = actual_demand.copy()\n",
    "    if 'CPU' in server_generation:\n",
    "        if server_generation in ['CPU.S1']:\n",
    "            continue\n",
    "        slots_size = 2\n",
    "    else:\n",
    "        slots_size = 4\n",
    "\n",
    "    if latency_sensitivity == 'low':\n",
    "        datacenter_id = 'DC1'\n",
    "    elif latency_sensitivity == 'medium':\n",
    "        datacenter_id = 'DC2'\n",
    "    elif latency_sensitivity == 'high':\n",
    "        datacenter_id = 'DC3'\n",
    "\n",
    "    print(f\"Server generation: {server_generation}, Latency sensitivity: {latency_sensitivity}\")\n",
    "    while True:\n",
    "        # 1) Find the ranges of time steps between which this server/latency is in demand\n",
    "        relevant_demand = remaining_demand.query(f'server_generation == @server_generation and {latency_sensitivity} > 0')\n",
    "        # print(relevant_demand)\n",
    "        time_steps_of_demand = relevant_demand.get('time_step').to_numpy()\n",
    "        # print(time_steps_of_demand)\n",
    "\n",
    "        # # DEBUG\n",
    "        # # Rmove a single time step from the middle of the range (to prove this step works for ranges with gaps of no demand)\n",
    "        # time_steps_of_demand = np.delete(time_steps_of_demand, 20)\n",
    "        # time_steps_of_demand = np.delete(time_steps_of_demand, 20)\n",
    "        # time_steps_of_demand = np.delete(time_steps_of_demand, 20)\n",
    "        # time_steps_of_demand = np.delete(time_steps_of_demand, 20)\n",
    "        # time_steps_of_demand = np.delete(time_steps_of_demand, 20)\n",
    "        # time_steps_of_demand = np.delete(time_steps_of_demand, 30)\n",
    "        # time_steps_of_demand = np.delete(time_steps_of_demand, 58)\n",
    "\n",
    "        time_steps_diff = np.diff(time_steps_of_demand)\n",
    "        gap_indices = np.append(np.where(time_steps_diff > 1), len(time_steps_of_demand) - 1)\n",
    "\n",
    "        ranges = []\n",
    "        start = 0\n",
    "        for gap in gap_indices:\n",
    "            ranges.append((time_steps_of_demand[start], time_steps_of_demand[gap]))\n",
    "            start = gap + 1\n",
    "\n",
    "        # print(ranges)\n",
    "\n",
    "        # 2) Merge ranges which have a negligibly small gap in between (relative to the length of the smallest range)\n",
    "        i = 0\n",
    "        while i < len(ranges) - 1:\n",
    "            length = ranges[i][1] - ranges[i][0]\n",
    "            length_next = ranges[i + 1][1] - ranges[i + 1][0]\n",
    "            if ranges[i + 1][0] - ranges[i][1] < (min(length, length_next)/4 * 17):\n",
    "                ranges[i] = (ranges[i][0], ranges[i + 1][1])\n",
    "                ranges.pop(i + 1)\n",
    "            else:\n",
    "                i += 1\n",
    "        # print(ranges)\n",
    "\n",
    "        # 3) Filter all ranges which last for less than the time it takes for the server/latency to break even\n",
    "        break_even_time = break_even_time_all[server_generation][latency_sensitivity]\n",
    "        ranges = [r for r in ranges if r[1] - r[0] >= (2*break_even_time)]\n",
    "\n",
    "        # print(ranges)\n",
    "\n",
    "        \n",
    "        # 3) For each range (from longest to shortest):\n",
    "        sorted_ranges_i = np.argsort([r[1] - r[0] for r in ranges])\n",
    "        for i in reversed(sorted_ranges_i):\n",
    "            # i = 2\n",
    "            current_range = ranges[i]\n",
    "            # print(range)\n",
    "\n",
    "            # 1) Calculate the minimum demand across that range\n",
    "            demand_in_range = relevant_demand.query(f'time_step >= @current_range[0] and time_step <= @current_range[1]')\n",
    "            min_demand = demand_in_range.min()[latency_sensitivity]\n",
    "            # 2) Calculate the number of servers to buy meet the minimum demand\n",
    "            capacity = servers.set_index('server_generation').loc[server_generation]['capacity']\n",
    "            desired_buy_count = int(np.round(min_demand / capacity))\n",
    "\n",
    "            # print(f\"{min_demand}/{capacity} = {min_demand / capacity} ~~ {str(desired_buy_count)} GPUs to buy\")\n",
    "\n",
    "\n",
    "            # 4) Store the number of servers to buy, which data centre, the buy time step, the dismiss time step\n",
    "            results.append({\n",
    "                'server_generation': server_generation,\n",
    "                'buy_count': str(desired_buy_count),\n",
    "                'datacenter_id': datacenter_id,\n",
    "                'buy_time_step': str(current_range[0]),\n",
    "                'dismiss_time_step': str(current_range[1] + 1)\n",
    "            })\n",
    "\n",
    "\n",
    "            # 5) For each demand in the range, subtract the capacity * number of servers to buy\n",
    "            demand_to_subtract = desired_buy_count * capacity\n",
    "            # print(f\"Subtracting {demand_to_subtract} from the demand in the range\")\n",
    "            for index, row in demand_in_range.iterrows():\n",
    "                remaining = row[latency_sensitivity] - demand_to_subtract\n",
    "                remaining_demand.at[index, latency_sensitivity] = remaining\n",
    "\n",
    "\n",
    "            # 6) Filter new demand values which are too low to buy at least 1 server for\n",
    "            remaining_demand = remaining_demand.query(f'{latency_sensitivity} > {(capacity / 2) + 1}')\n",
    "\n",
    "\n",
    "            # break\n",
    "        # 4) Repeat steps 1.1 to 1.3.4 with the new demand values until there are no ranges after 1.2\n",
    "        if len(ranges) == 0:\n",
    "            # print(\"No more ranges of demand to satisfy\")\n",
    "            results_df = pd.DataFrame(results)\n",
    "            total_servers_bought = results_df['buy_count'].astype(int).sum()\n",
    "            print(f\"Total servers bought: {total_servers_bought}\")\n",
    "            break\n",
    "\n",
    "# save_json('./results.json', results)\n",
    "save_results_as_actions('./gpuall_cpus432_min_length_x2_merge_threshold_x17_seed_123.json', results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
