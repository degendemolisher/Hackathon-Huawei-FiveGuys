{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import Random\n",
    "import pandas as pd\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from seeds import known_seeds\n",
    "import evaluation\n",
    "import utils\n",
    "from action import ActionSpace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[290040, 982514, 638034,    829, 532525, 148709, 894464],\n",
       "       [558536, 491094, 988437, 162395,  95521, 161162,  36496],\n",
       "       [982841, 656695,  30087, 691538, 736235, 377057, 248982],\n",
       "       [870381, 214594, 603002, 144074, 903814, 981159, 112335],\n",
       "       [805681,  79759, 247019, 633656, 745739, 419686, 525811],\n",
       "       [421503, 475723, 520102,  53846, 456611, 858085, 425878]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "space = spaces.Box(low=0, high=1000000, shape=(6, 7), dtype=np.int32)\n",
    "space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "    #old fleet function\n",
    "    def init_fleet(self):\n",
    "        fleet = {\"DC1\":{},\"DC2\":{},\"DC3\":{},\"DC4\":{}}\n",
    "        for i in fleet.keys():\n",
    "            for j in self.server_generations:\n",
    "                fleet[i].update(j, {})\n",
    "                fleet[i][j].update(\"servers\", [])\n",
    "                fleet[i][j].update(\"timestep_bought\", [])\n",
    "                fleet[i][j].update(\"total_owned\", 0)\n",
    "        return fleet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 1, 1, 2, 1, 3],\n",
       "       [2, 0, 0, 3, 3, 0, 2],\n",
       "       [3, 2, 0, 2, 1, 1, 2],\n",
       "       [1, 3, 2, 1, 2, 3, 1]], dtype=int32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "action_space = spaces.Box(low=0, high=3, shape=(4,7), dtype=np.int32)\n",
    "action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gymnasium.wrappers import FlattenObservation # type: ignore\n",
    "class CustomEnv(gym.Env):\n",
    "    def __init__(self):\n",
    "        #super(self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        define self.actionspace and self.observation_space below using \n",
    "        variables available in \"gym.spaces\"\n",
    "        \"\"\"\n",
    "\n",
    "        #agent action space (actions it can make)\n",
    "        #datacenter, servergen, action, where the action corresponds to the chosen number e.g. 0 = buy, 1=move etc\n",
    "        self.action_space = spaces.Box(low=0, high=3, shape=(4,7), dtype=np.int32)\n",
    "        \n",
    "        self.default_demand, self.datacenters, self.servers, self.selling_prices = utils.load_problem_data()\n",
    "\n",
    "        self.fleet_columns = ['datacenter_id', 'server_generation', 'server_id', 'action',\n",
    "       'server_type', 'release_time', 'purchase_price', 'slots_size', 'energy_consumption', \n",
    "       'capacity', 'life_expectancy', 'cost_of_moving','average_maintenance_fee', 'cost_of_energy',\n",
    "       'latency_sensitivity', 'slots_capacity', 'selling_price', 'lifespan', 'moved']\n",
    "\n",
    "        #agent observation space (what the agent can \"see\"/information that is fed to agent)\n",
    "        #a 3d array of latency, server_gen, demand, concatenated with \n",
    "        #a 3d array of latency, server_gen, supply\n",
    "        self.observation_space = spaces.Box(low=0, high=1000000, shape=(6, 7), dtype=np.int32)\n",
    "\n",
    "        self.seeds_array = known_seeds(\"training\")\n",
    "        self.seed_counter = 0\n",
    "\n",
    "        self.server_generations = ['CPU.S1', 'CPU.S2', 'CPU.S3', 'CPU.S4', 'GPU.S1', 'GPU.S2', 'GPU.S3']\n",
    "        self.latencies = ['low', 'medium', 'high']\n",
    "        self.data_centers = ['DC1', 'DC2', 'DC3', 'DC4']\n",
    "\n",
    "    #might need func below to convert agent action into a relevant action\n",
    "    #def conv_agent_action_to_move(self, action):\n",
    "    \n",
    "    #returns mask for the action space based on possible plays\n",
    "    #def valid_action_mask(self):\n",
    "    \n",
    "    #initiallise/reset all of the base variables at the end of the \"game\"\n",
    "    #has to return a base/initial observation\n",
    "\n",
    "    def convert_demand_to_observation(self, demand):\n",
    "        demand_observation = np.zeros((3,7), np.int32)\n",
    "        for i in range(len(self.server_generations)):\n",
    "            servergen_demand = demand[demand[\"server_generation\"] == self.server_generations[i]]\n",
    "            for j in range(len(self.latencies)):\n",
    "                latency_demand = servergen_demand[self.latencies[j]]\n",
    "                demand_observation[j][i] = latency_demand.sum()\n",
    "        return demand_observation\n",
    "\n",
    "    def convert_fleet_to_observation(self, fleet):\n",
    "        observed_fleet = np.zeros((3,7), np.int32)\n",
    "        for i in range(len(self.data_centers[0:3])):\n",
    "            for j in range(len(self.server_generations)):\n",
    "                #filter for the datacenter\n",
    "                filtered_dc = fleet[fleet[\"datacenter_id\"] == self.data_centers[i]]\n",
    "                #get sum of the server generation\n",
    "                gen_total = filtered_dc[filtered_dc[\"server_generation\"] == self.server_generations[j]].shape[0]\n",
    "                if(self.server_generations[i] == \"DC3\"):\n",
    "                    #get dc4 and add onto dc3 total\n",
    "                    filtered_dc = fleet[fleet[\"datacenter_id\"] == self.datacenters[i+1]]\n",
    "                    gen_total += filtered_dc[filtered_dc[\"server_generation\"] == self.server_generations[j]].shape[0]\n",
    "                observed_fleet[i][j] = gen_total\n",
    "        return observed_fleet\n",
    "\n",
    "    def init_fleet(self):\n",
    "        self.fleet = pd.DataFrame(columns=self.fleet_columns)\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        self.timestep = 1\n",
    "        self.seed_counter += 1\n",
    "        self.seed_counter %= 10\n",
    "        np.random.seed(self.seeds_array[self.seed_counter])\n",
    "\n",
    "        self.actionspace = ActionSpace()\n",
    "        self.OBJECTIVE = 0\n",
    "\n",
    "        self.init_fleet()\n",
    "        self.demand = evaluation.get_actual_demand(self.default_demand)\n",
    "        self.timestep_demand = self.demand[self.demand[\"time_step\"] == self.timestep]\n",
    "        observation_demand = self.convert_demand_to_observation(self.timestep_demand)\n",
    "        observation_fleet = self.convert_fleet_to_observation(self.fleet)\n",
    "        observation = np.concatenate((observation_demand, observation_fleet))\n",
    "        self.done = False\n",
    "        return observation, {}\n",
    "\n",
    "    # def buy_demand(self, datacenter, server_gen, timestep_demand):\n",
    "    #     self.fleet\n",
    "    \n",
    "    #buys \"number\" amount of servers at datacenter\n",
    "    #NO VALIDITY CHECKS RIGHT NOW\n",
    "    def buy(self, datacenter, server_gen, number=10):\n",
    "        ts_fleet = pd.DataFrame(columns=self.fleet_columns[0:3])\n",
    "        fleet_array = []\n",
    "        datacenter_array =[]\n",
    "        server_gen_array=[]\n",
    "        buy_array=[]\n",
    "        server_id_array=[]\n",
    "        for i in range(number):\n",
    "            server_id = self.actionspace.generate_server_id(server_gen)\n",
    "            datacenter_array.append(datacenter)\n",
    "            server_gen_array.append(server_gen)\n",
    "            server_id_array.append(server_id)\n",
    "            buy_array.append(\"buy\")\n",
    "            fleet_array.append([datacenter, server_gen, server_id, \"buy\"])\n",
    "        temp = pd.DataFrame({\"datacenter_id\":datacenter_array, \"server_generation\":server_gen_array,\n",
    "         \"server_id\": server_id_array, \"action\": buy_array})\n",
    "\n",
    "\n",
    "        ts_fleet = pd.concat([ts_fleet, temp])\n",
    "        ts_fleet = ts_fleet.merge(self.servers, on='server_generation', how='left')\n",
    "        ts_fleet = ts_fleet.merge(self.datacenters, on='datacenter_id', how='left')\n",
    "        ts_fleet = ts_fleet.merge(self.selling_prices, \n",
    "                            on=['server_generation', 'latency_sensitivity'], \n",
    "                            how='left')\n",
    "        ts_fleet.fillna(0)\n",
    "        self.fleet = pd.concat([self.fleet, ts_fleet])\n",
    "\n",
    "    #called in a loop where each time it is called the agent chooses an action and change\n",
    "    #state of game appropriately according to agent action\n",
    "    def step(self, action):\n",
    "        \"\"\"\n",
    "        after agent move, do it, calc the new observation state\n",
    "        and the reward from that move it made, if \"end\" of game set self.done to True\n",
    "\n",
    "        \"\"\"\n",
    "        selling_prices = evaluation.change_selling_prices_format(self.selling_prices)\n",
    "\n",
    "        actions = self.actionspace.convert_actionspace_to_actionV2(action)\n",
    "\n",
    "        for i in actions:\n",
    "            if(i[0] == \"buy\"):\n",
    "                self.buy(datacenter = i[3], server_gen = i[1])\n",
    "\n",
    "        \n",
    "        Zf = evaluation.get_capacity_by_server_generation_latency_sensitivity(self.fleet)\n",
    "        D = evaluation.get_time_step_demand(self.demand, self.timestep)\n",
    "        U = evaluation.get_utilization(D, Zf)\n",
    "        #check if fleet is empty\n",
    "        if self.fleet.shape[0] > 0:\n",
    "            # get the server capacity at timestep\n",
    "            Zf = evaluation.get_capacity_by_server_generation_latency_sensitivity(self.fleet)\n",
    "\n",
    "            # evaluate objective function at current timestep\n",
    "            U = evaluation.get_utilization(D, Zf)\n",
    "    \n",
    "            L = evaluation.get_normalized_lifespan(self.fleet)\n",
    "    \n",
    "            P = evaluation.get_profit(D, \n",
    "                           Zf, \n",
    "                           selling_prices,\n",
    "                           self.fleet)\n",
    "                           \n",
    "            o = U * L * P\n",
    "\n",
    "            self.OBJECTIVE += o\n",
    "            reward = U + L + P + o + (self.OBJECTIVE/self.timestep)\n",
    "        else:\n",
    "            reward = -5\n",
    "        #reached final timestep\n",
    "        if(self.timestep == 168):\n",
    "            self.done = True\n",
    "        self.timestep += 1\n",
    "\n",
    "        #extra info on the game if wanted for yourself\n",
    "        info = {}\n",
    "        truncated = False\n",
    "        \n",
    "        self.timestep_demand = self.demand[self.demand[\"time_step\"] == self.timestep]\n",
    "        \n",
    "        observation_demand = self.convert_demand_to_observation(self.timestep_demand)\n",
    "        observation_fleet = self.convert_fleet_to_observation(self.fleet)\n",
    "        observation = np.concatenate((observation_demand, observation_fleet))\n",
    "\n",
    "        return (observation, reward, self.done, truncated, info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omerk/projects/huawei/Hackathon-Huawei/.venv/lib/python3.9/site-packages/stable_baselines3/common/env_checker.py:263: UserWarning: Your observation  has an unconventional shape (neither an image, nor a 1D vector). We recommend you to flatten the observation to have only a 1D vector or use a custom policy to properly process the data.\n",
      "  warnings.warn(\n",
      "/Users/omerk/projects/huawei/Hackathon-Huawei/.venv/lib/python3.9/site-packages/stable_baselines3/common/env_checker.py:453: UserWarning: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) cf. https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\n",
      "  warnings.warn(\n",
      "/Users/omerk/projects/huawei/Hackathon-Huawei/.venv/lib/python3.9/site-packages/stable_baselines3/common/env_checker.py:464: UserWarning: Your action space has dtype int32, we recommend using np.float32 to avoid cast errors.\n",
      "  warnings.warn(\n",
      "/var/folders/cc/c3cqjy4s7zqfh4q58lfmvkq80000gn/T/ipykernel_36739/239433756.py:118: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self.fleet = pd.concat([self.fleet, ts_fleet])\n",
      "/var/folders/cc/c3cqjy4s7zqfh4q58lfmvkq80000gn/T/ipykernel_36739/239433756.py:118: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self.fleet = pd.concat([self.fleet, ts_fleet])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc\n",
      "def\n",
      "ghi\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "abc\n",
      "def\n",
      "ghi\n"
     ]
    }
   ],
   "source": [
    "from stable_baselines3.common.env_checker import check_env\n",
    "env = CustomEnv()\n",
    "check_env(env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from stable_baselines3 import A2C\n",
    "def train():\n",
    "    #directory model and log saved to\n",
    "    model_dir = f\"models/V2/{int(time.time())}/\"\n",
    "    log_dir = f\"logs/V2/{int(time.time())}/\"\n",
    "\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "\n",
    "    if not os.path.exists(log_dir):\n",
    "        os.makedirs(log_dir)\n",
    "\n",
    "    env = CustomEnv()\n",
    "    #wrap for action masking\n",
    "    #env = ActionMasker(env, mask_fn) \n",
    "    env.reset()\n",
    "\n",
    "    model = A2C('MlpPolicy', env, verbose=1, tensorboard_log=log_dir)\n",
    "    #model = PPO(MaskableActorCriticPolicy, env, verbose=1, tensorboard_log=log_dir)\n",
    "\n",
    "    TIMESTEPS = 10000\n",
    "    #adjust the range below to adjust timesteps it runs for (calc stepcount as max range val * timesteps)\n",
    "    #saves model every TIMESTEPS number of steps\n",
    "    for i in range(1,50):\n",
    "        model.learn(total_timesteps=TIMESTEPS, reset_num_timesteps=False, tb_log_name=f\"PPO\")\n",
    "        model.save(f\"{model_dir}/{TIMESTEPS*i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/omerk/projects/huawei/Hackathon-Huawei/.venv/lib/python3.9/site-packages/stable_baselines3/common/env_checker.py:263: UserWarning: Your observation  has an unconventional shape (neither an image, nor a 1D vector). We recommend you to flatten the observation to have only a 1D vector or use a custom policy to properly process the data.\n",
      "  warnings.warn(\n",
      "/Users/omerk/projects/huawei/Hackathon-Huawei/.venv/lib/python3.9/site-packages/stable_baselines3/common/env_checker.py:453: UserWarning: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) cf. https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\n",
      "  warnings.warn(\n",
      "/Users/omerk/projects/huawei/Hackathon-Huawei/.venv/lib/python3.9/site-packages/stable_baselines3/common/env_checker.py:464: UserWarning: Your action space has dtype int32, we recommend using np.float32 to avoid cast errors.\n",
      "  warnings.warn(\n",
      "/var/folders/cc/c3cqjy4s7zqfh4q58lfmvkq80000gn/T/ipykernel_36739/239433756.py:118: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self.fleet = pd.concat([self.fleet, ts_fleet])\n",
      "/var/folders/cc/c3cqjy4s7zqfh4q58lfmvkq80000gn/T/ipykernel_36739/239433756.py:118: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  self.fleet = pd.concat([self.fleet, ts_fleet])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abc\n",
      "def\n",
      "ghi\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "action [[1 0 1 1 0 2 3]\n",
      " [0 3 3 3 2 2 0]\n",
      " [2 1 1 3 1 1 2]\n",
      " [1 1 1 3 3 3 0]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 631060.175061247\n",
      "action [[3 1 1 2 2 1 3]\n",
      " [1 3 0 1 1 3 2]\n",
      " [2 3 3 3 3 2 1]\n",
      " [0 1 2 0 3 3 1]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 656575.1755022192\n",
      "action [[0 1 3 0 2 3 1]\n",
      " [1 2 1 1 1 2 0]\n",
      " [3 1 3 3 1 2 1]\n",
      " [0 3 1 1 3 0 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 563770.1752269262\n",
      "action [[2 0 3 3 0 0 2]\n",
      " [0 1 3 3 3 0 3]\n",
      " [3 1 0 2 3 2 3]\n",
      " [0 2 3 0 3 1 3]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 683215.1764161614\n",
      "action [[1 0 1 0 2 0 3]\n",
      " [3 3 1 2 3 3 1]\n",
      " [0 0 1 2 3 0 1]\n",
      " [2 0 1 1 1 2 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 949315.1936944749\n",
      "action [[1 2 1 1 1 3 3]\n",
      " [0 0 2 3 0 0 0]\n",
      " [1 1 2 0 2 1 2]\n",
      " [2 3 0 3 2 1 1]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 1264450.2068102213\n",
      "action [[3 0 3 3 1 3 3]\n",
      " [3 2 1 1 1 1 1]\n",
      " [2 2 2 3 0 2 0]\n",
      " [1 3 1 2 0 3 1]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 1455010.2184069166\n",
      "action [[2 2 1 0 3 3 1]\n",
      " [2 3 3 2 2 1 2]\n",
      " [3 1 3 2 1 1 0]\n",
      " [2 2 2 2 3 3 3]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 1774285.2311268677\n",
      "action [[2 1 2 0 1 0 0]\n",
      " [0 3 2 0 0 0 2]\n",
      " [0 0 3 1 0 3 2]\n",
      " [3 0 0 0 1 1 1]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 1987645.233321562\n",
      "action [[1 1 3 1 3 1 2]\n",
      " [1 1 3 3 2 2 1]\n",
      " [0 2 2 0 0 1 1]\n",
      " [1 2 0 3 3 2 1]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 2491135.250022544\n",
      "action [[3 3 3 1 1 0 1]\n",
      " [2 2 3 0 0 3 3]\n",
      " [0 0 0 3 0 2 2]\n",
      " [2 2 2 1 0 0 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 2555785.241298397\n",
      "action [[0 2 1 3 2 0 1]\n",
      " [1 2 3 1 2 1 3]\n",
      " [2 3 0 3 2 0 3]\n",
      " [1 0 0 0 2 2 0]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 2772265.2492613816\n",
      "action [[3 1 1 1 2 2 2]\n",
      " [0 1 0 0 3 0 1]\n",
      " [3 2 0 2 3 3 0]\n",
      " [3 1 1 1 2 0 3]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 2506540.242937538\n",
      "action [[3 2 3 1 1 1 1]\n",
      " [2 1 0 1 1 3 0]\n",
      " [3 2 1 0 2 3 1]\n",
      " [1 3 0 0 0 3 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 2777515.2467483017\n",
      "action [[2 0 1 0 2 0 1]\n",
      " [1 1 2 2 3 0 0]\n",
      " [0 1 1 1 0 1 1]\n",
      " [1 1 1 1 0 1 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 2867185.2502299906\n",
      "action [[1 2 0 1 2 1 0]\n",
      " [2 2 0 0 0 1 2]\n",
      " [0 3 3 1 3 0 0]\n",
      " [3 0 2 1 2 0 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 3127210.254858415\n",
      "action [[1 3 0 2 2 2 0]\n",
      " [0 3 1 2 2 1 0]\n",
      " [2 1 0 3 3 3 3]\n",
      " [2 0 1 1 0 3 0]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 3267970.256096097\n",
      "action [[1 0 1 3 1 3 1]\n",
      " [1 2 3 2 2 1 0]\n",
      " [2 2 0 0 2 1 3]\n",
      " [1 2 1 1 2 3 1]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 3406330.2588177873\n",
      "action [[1 3 0 2 2 1 0]\n",
      " [2 2 1 2 2 2 3]\n",
      " [1 1 2 1 2 0 2]\n",
      " [3 3 3 2 0 0 1]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 3089335.2508187103\n",
      "action [[1 1 3 0 1 3 3]\n",
      " [2 1 3 2 1 2 0]\n",
      " [3 3 0 0 0 0 0]\n",
      " [1 2 2 0 0 1 1]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 3378955.255404806\n",
      "action [[2 2 2 3 3 0 0]\n",
      " [3 0 1 0 1 2 3]\n",
      " [0 1 0 2 0 0 0]\n",
      " [2 0 1 3 2 1 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 4107295.269615404\n",
      "action [[0 1 0 1 1 1 0]\n",
      " [3 1 3 1 0 1 2]\n",
      " [0 3 3 3 0 2 2]\n",
      " [2 2 3 3 3 1 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 4774360.2729483275\n",
      "action [[0 1 2 1 0 3 0]\n",
      " [2 1 3 2 1 3 0]\n",
      " [1 3 2 3 2 0 2]\n",
      " [1 0 2 1 0 0 3]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 4980070.2767290715\n",
      "action [[0 1 3 3 2 1 2]\n",
      " [1 0 3 2 3 0 3]\n",
      " [3 1 2 0 1 3 0]\n",
      " [1 0 1 3 1 0 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 5636695.285714285\n",
      "action [[3 0 0 0 2 3 1]\n",
      " [0 2 3 1 2 3 0]\n",
      " [1 0 1 0 1 2 0]\n",
      " [3 2 1 0 3 1 0]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 5542450.248691659\n",
      "action [[2 0 0 2 0 2 3]\n",
      " [3 3 0 2 3 2 0]\n",
      " [1 0 2 3 2 1 3]\n",
      " [1 3 1 1 2 0 0]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 5765695.285714285\n",
      "action [[2 0 0 3 1 1 1]\n",
      " [2 0 3 3 3 3 0]\n",
      " [3 3 1 1 0 0 3]\n",
      " [2 2 3 3 2 2 1]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 6007485.336739763\n",
      "action [[2 2 0 0 3 2 2]\n",
      " [0 1 2 0 1 0 1]\n",
      " [3 3 2 1 2 3 3]\n",
      " [2 3 3 2 1 1 1]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 6097720.384396162\n",
      "action [[1 2 3 1 3 0 1]\n",
      " [2 0 2 3 2 0 2]\n",
      " [1 2 2 0 1 3 3]\n",
      " [1 2 3 0 0 3 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 6259770.384515686\n",
      "action [[1 0 0 3 0 1 2]\n",
      " [1 2 1 3 2 0 3]\n",
      " [1 2 0 0 0 0 1]\n",
      " [2 3 3 1 0 0 3]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 6690420.384986311\n",
      "action [[3 3 1 0 0 2 0]\n",
      " [3 3 1 3 0 0 2]\n",
      " [3 0 0 3 0 0 2]\n",
      " [2 2 1 1 1 2 1]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 7088420.383859122\n",
      "action [[3 2 0 2 2 3 0]\n",
      " [1 1 2 2 2 2 0]\n",
      " [0 2 1 2 3 2 1]\n",
      " [0 1 0 1 2 0 0]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 7100895.381386275\n",
      "action [[0 3 2 1 2 1 2]\n",
      " [3 0 3 3 0 2 2]\n",
      " [1 1 1 1 2 0 0]\n",
      " [2 2 3 0 0 1 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 7406695.381971857\n",
      "action [[0 3 1 1 0 1 1]\n",
      " [2 3 1 1 2 0 0]\n",
      " [3 2 1 0 1 0 1]\n",
      " [1 2 3 3 0 1 1]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 7688345.382769094\n",
      "action [[0 2 2 2 2 3 2]\n",
      " [3 2 2 0 0 3 3]\n",
      " [3 0 1 3 1 0 1]\n",
      " [2 3 2 1 1 2 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 7908045.393274047\n",
      "action [[3 2 2 1 3 1 0]\n",
      " [1 1 3 3 0 0 2]\n",
      " [0 2 3 1 0 2 1]\n",
      " [2 2 2 0 1 3 0]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 8115270.380952381\n",
      "action [[1 2 2 0 3 3 2]\n",
      " [2 3 3 0 3 3 3]\n",
      " [0 2 1 2 2 0 2]\n",
      " [0 1 1 3 2 3 1]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 8295945.401094145\n",
      "action [[3 3 1 2 0 2 0]\n",
      " [1 3 0 0 3 0 1]\n",
      " [1 1 0 1 2 2 0]\n",
      " [1 2 3 2 2 0 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 8469920.408309355\n",
      "action [[0 3 0 0 0 2 0]\n",
      " [2 3 0 3 1 1 0]\n",
      " [2 1 0 0 2 0 2]\n",
      " [1 0 1 3 1 0 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 9055085.431156557\n",
      "action [[1 2 1 1 2 3 0]\n",
      " [0 0 3 0 2 0 2]\n",
      " [0 2 2 1 2 1 0]\n",
      " [0 1 3 0 3 2 1]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 9107195.43216838\n",
      "action [[1 1 0 3 0 1 3]\n",
      " [2 1 1 2 3 0 2]\n",
      " [3 3 3 2 2 1 1]\n",
      " [2 3 2 2 2 3 3]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 9235245.41729983\n",
      "action [[1 2 2 2 1 3 1]\n",
      " [1 1 0 0 2 3 3]\n",
      " [0 1 1 3 0 2 1]\n",
      " [1 0 3 3 2 3 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 9479495.406473607\n",
      "action [[3 1 3 0 1 1 0]\n",
      " [1 1 1 1 0 0 0]\n",
      " [3 3 2 1 1 2 2]\n",
      " [1 1 0 1 1 1 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 9514295.386744903\n",
      "action [[1 3 2 0 0 1 1]\n",
      " [2 1 1 3 2 1 0]\n",
      " [0 2 0 0 1 2 3]\n",
      " [3 3 2 2 2 2 1]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 10011420.426615072\n",
      "action [[2 3 1 0 1 0 0]\n",
      " [3 1 2 0 2 1 2]\n",
      " [2 1 1 2 1 1 2]\n",
      " [2 0 0 1 1 1 1]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 9924555.401386162\n",
      "action [[0 1 2 0 2 2 2]\n",
      " [1 1 2 2 2 0 1]\n",
      " [1 0 2 1 1 0 2]\n",
      " [1 2 2 0 2 0 3]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 10042945.407404248\n",
      "action [[1 1 1 2 3 3 0]\n",
      " [1 0 2 0 1 3 1]\n",
      " [0 3 1 3 3 0 2]\n",
      " [3 0 1 2 0 1 1]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 10436620.427539403\n",
      "action [[1 3 2 3 0 3 2]\n",
      " [2 1 0 3 1 1 2]\n",
      " [1 1 3 3 2 0 0]\n",
      " [3 2 0 1 3 0 0]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 10545545.442414539\n",
      "action [[2 0 0 1 1 2 3]\n",
      " [0 2 2 1 0 1 1]\n",
      " [2 2 1 1 1 3 0]\n",
      " [2 3 3 1 0 3 0]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 11219685.446245842\n",
      "action [[3 0 2 3 2 1 2]\n",
      " [1 0 2 0 3 3 0]\n",
      " [2 1 1 3 1 1 3]\n",
      " [3 1 0 3 2 1 3]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 10836555.435702851\n",
      "action [[1 1 1 1 2 1 0]\n",
      " [3 1 3 0 0 0 0]\n",
      " [2 2 0 2 1 0 2]\n",
      " [3 0 2 2 3 1 3]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 10585825.426749839\n",
      "action [[2 1 1 1 3 3 0]\n",
      " [2 1 0 2 2 0 2]\n",
      " [1 1 1 1 3 3 0]\n",
      " [0 3 0 2 3 1 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 11342685.439994289\n",
      "action [[1 2 1 1 2 3 3]\n",
      " [3 2 2 0 2 0 0]\n",
      " [1 0 1 2 2 3 3]\n",
      " [2 2 1 1 0 0 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 11690695.448925944\n",
      "action [[1 2 2 1 1 3 1]\n",
      " [3 2 0 3 2 1 2]\n",
      " [1 1 2 0 3 0 1]\n",
      " [3 1 1 0 0 2 1]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 11505095.440251082\n",
      "action [[1 3 1 3 3 0 0]\n",
      " [1 3 2 3 0 1 0]\n",
      " [1 1 2 3 2 2 2]\n",
      " [3 3 2 2 0 1 1]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 12081895.448310183\n",
      "action [[0 0 1 1 2 0 3]\n",
      " [1 0 2 2 2 2 2]\n",
      " [0 1 2 3 3 0 0]\n",
      " [1 3 2 1 1 2 1]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 12084745.441643212\n",
      "action [[0 3 2 3 0 2 2]\n",
      " [1 0 0 1 1 3 2]\n",
      " [0 2 2 1 2 0 1]\n",
      " [2 2 0 3 2 3 3]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 12085095.437515661\n",
      "action [[0 3 2 1 0 3 1]\n",
      " [3 0 3 1 0 1 0]\n",
      " [3 2 3 1 2 3 0]\n",
      " [2 2 1 3 0 1 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 13406045.452475514\n",
      "action [[0 1 3 0 2 1 0]\n",
      " [3 2 2 0 0 3 2]\n",
      " [1 0 3 0 1 2 3]\n",
      " [3 3 0 0 0 3 3]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 13232715.4198159\n",
      "action [[2 2 3 0 3 3 0]\n",
      " [3 1 2 2 2 2 0]\n",
      " [0 1 2 1 1 0 1]\n",
      " [2 2 1 0 0 1 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 13736815.454719588\n",
      "action [[3 1 0 2 1 2 3]\n",
      " [2 1 3 3 2 0 3]\n",
      " [3 0 0 2 2 2 0]\n",
      " [2 1 0 2 0 0 0]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 13805685.448962023\n",
      "action [[3 0 3 2 2 1 3]\n",
      " [2 2 0 1 3 0 0]\n",
      " [0 1 0 0 1 1 2]\n",
      " [0 0 2 3 0 2 0]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 14062215.445521384\n",
      "action [[2 2 0 2 2 3 0]\n",
      " [1 2 2 3 2 1 0]\n",
      " [0 0 1 0 2 1 3]\n",
      " [1 3 3 2 2 3 3]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 14743501.448272126\n",
      "action [[2 3 2 0 3 2 3]\n",
      " [1 0 0 2 3 1 3]\n",
      " [0 0 1 1 0 0 3]\n",
      " [2 2 2 0 1 0 1]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 15450747.515106792\n",
      "action [[3 1 2 3 0 2 1]\n",
      " [3 0 2 3 2 0 0]\n",
      " [1 1 3 3 3 0 2]\n",
      " [0 0 2 1 3 3 1]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 15402400.511289997\n",
      "action [[1 0 1 1 2 2 3]\n",
      " [2 2 1 2 2 3 0]\n",
      " [2 0 2 1 1 0 2]\n",
      " [2 2 0 2 1 1 1]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 15909138.512953952\n",
      "action [[3 0 1 0 3 2 2]\n",
      " [0 0 0 1 0 1 0]\n",
      " [0 3 3 2 0 1 1]\n",
      " [0 0 0 1 1 3 1]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 15828984.021055752\n",
      "action [[3 2 2 3 1 1 1]\n",
      " [2 0 2 2 3 1 1]\n",
      " [1 3 3 0 1 1 3]\n",
      " [0 0 3 1 0 3 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 16127860.034149079\n",
      "action [[2 3 1 2 1 3 1]\n",
      " [0 1 3 1 3 1 3]\n",
      " [1 3 2 2 0 1 0]\n",
      " [0 2 2 0 3 0 1]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 16571453.0252235\n",
      "action [[0 1 2 0 2 3 3]\n",
      " [3 2 2 3 1 2 0]\n",
      " [1 2 0 2 3 1 3]\n",
      " [0 0 1 0 3 3 0]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 17151279.539179802\n",
      "action [[1 1 1 2 1 0 2]\n",
      " [3 2 1 3 2 1 2]\n",
      " [1 0 2 1 2 1 3]\n",
      " [2 2 2 0 2 3 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 12311573.484511312\n",
      "action [[3 2 1 0 2 1 3]\n",
      " [2 0 1 2 0 3 1]\n",
      " [2 2 2 1 1 1 0]\n",
      " [2 0 1 3 2 3 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 12100931.988642018\n",
      "action [[2 1 2 0 1 1 1]\n",
      " [0 0 2 3 3 0 3]\n",
      " [1 0 2 2 3 0 3]\n",
      " [1 2 3 1 1 0 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 11953357.991905106\n",
      "action [[1 0 3 2 2 2 1]\n",
      " [3 2 1 2 3 0 2]\n",
      " [2 2 3 1 1 2 0]\n",
      " [2 3 0 1 2 3 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 12009419.496765226\n",
      "action [[0 2 0 0 3 1 2]\n",
      " [3 3 2 1 3 1 1]\n",
      " [1 1 2 3 2 1 1]\n",
      " [1 3 0 3 1 2 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 11632732.98805263\n",
      "action [[3 1 1 0 2 3 0]\n",
      " [0 2 1 2 1 0 0]\n",
      " [1 2 0 1 2 2 3]\n",
      " [2 0 0 2 2 3 0]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 12083544.986971768\n",
      "action [[2 1 0 3 1 2 1]\n",
      " [2 0 1 2 1 1 0]\n",
      " [2 0 1 3 0 1 3]\n",
      " [1 0 3 2 3 3 0]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 12855857.476151709\n",
      "action [[2 1 0 3 1 3 0]\n",
      " [3 2 0 0 1 0 0]\n",
      " [1 0 0 0 2 0 0]\n",
      " [3 2 1 1 1 3 1]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 13415785.505281784\n",
      "action [[2 0 1 2 3 3 1]\n",
      " [1 3 2 0 1 3 0]\n",
      " [0 0 2 0 3 0 1]\n",
      " [0 2 0 1 1 1 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 13369020.01222441\n",
      "action [[2 0 3 0 3 1 1]\n",
      " [1 2 3 0 0 3 3]\n",
      " [0 1 1 2 3 1 3]\n",
      " [0 3 0 3 2 2 1]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 13809987.514503386\n",
      "action [[0 0 3 2 3 2 0]\n",
      " [1 1 0 2 2 0 2]\n",
      " [3 1 3 3 2 3 2]\n",
      " [3 1 1 0 3 0 0]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 13520700.50615222\n",
      "action [[3 3 2 1 0 3 2]\n",
      " [0 2 3 3 3 3 1]\n",
      " [1 3 1 2 2 1 3]\n",
      " [0 0 3 0 3 3 1]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 14181406.512961103\n",
      "action [[2 2 0 3 3 3 0]\n",
      " [2 3 0 0 1 3 0]\n",
      " [0 2 1 1 3 3 2]\n",
      " [3 3 0 1 1 2 0]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 15658667.545077864\n",
      "action [[3 1 1 3 1 2 2]\n",
      " [0 1 2 3 2 3 0]\n",
      " [0 1 2 0 3 0 0]\n",
      " [0 2 2 1 2 1 3]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 16575915.568824379\n",
      "action [[3 1 3 1 2 2 2]\n",
      " [1 3 1 1 1 3 3]\n",
      " [0 1 0 3 2 3 2]\n",
      " [0 0 2 0 0 2 1]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 16184491.558822462\n",
      "action [[3 1 3 3 2 1 0]\n",
      " [1 2 0 3 1 0 2]\n",
      " [1 1 0 0 0 2 2]\n",
      " [2 2 1 3 0 3 1]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 17516915.580426138\n",
      "action [[0 2 3 1 3 1 0]\n",
      " [3 2 2 2 2 1 2]\n",
      " [2 1 0 2 1 2 0]\n",
      " [1 3 3 3 1 2 0]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 15149545.546999907\n",
      "action [[3 3 0 0 3 3 1]\n",
      " [2 2 0 3 0 0 3]\n",
      " [2 1 2 2 1 0 2]\n",
      " [3 2 0 3 2 3 0]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 14720675.528751176\n",
      "action [[0 2 3 1 0 0 1]\n",
      " [1 0 3 2 3 1 0]\n",
      " [1 3 0 2 1 2 1]\n",
      " [0 2 1 2 3 3 0]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 14608756.020187063\n",
      "action [[0 0 1 2 2 2 0]\n",
      " [0 2 3 1 1 3 3]\n",
      " [0 2 1 0 0 3 0]\n",
      " [1 0 3 3 2 2 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 15351179.02500291\n",
      "action [[1 1 0 2 3 2 0]\n",
      " [0 1 2 0 0 0 3]\n",
      " [3 2 2 2 2 1 1]\n",
      " [2 2 0 0 1 2 0]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 14755553.495714609\n",
      "action [[0 3 0 3 2 2 1]\n",
      " [1 3 0 3 3 1 2]\n",
      " [2 0 0 0 2 1 2]\n",
      " [3 0 0 1 0 1 1]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 13981357.474297538\n",
      "action [[3 0 1 2 0 1 2]\n",
      " [0 0 2 0 1 0 2]\n",
      " [2 0 1 2 2 1 0]\n",
      " [3 2 0 1 2 1 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 13903854.478920244\n",
      "action [[2 0 2 3 3 1 0]\n",
      " [0 3 3 0 1 0 3]\n",
      " [0 1 0 0 0 1 1]\n",
      " [2 2 0 1 1 1 0]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 13623849.471290633\n",
      "action [[3 2 2 1 2 0 3]\n",
      " [0 0 3 1 3 3 3]\n",
      " [3 0 1 3 2 0 1]\n",
      " [0 1 1 3 2 2 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 13798509.966735873\n",
      "action [[2 1 3 2 2 1 3]\n",
      " [2 2 3 1 1 3 1]\n",
      " [2 3 3 1 1 1 1]\n",
      " [3 0 3 2 0 0 3]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 13421491.939295447\n",
      "action [[1 3 1 1 2 2 3]\n",
      " [3 3 2 2 1 2 3]\n",
      " [3 2 3 1 0 3 0]\n",
      " [3 2 2 2 1 2 0]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 12812870.943807272\n",
      "action [[1 2 3 2 2 1 3]\n",
      " [0 2 3 2 2 2 2]\n",
      " [3 0 3 1 0 3 3]\n",
      " [3 1 1 1 1 2 3]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 12584825.460865613\n",
      "action [[3 2 3 0 3 0 2]\n",
      " [0 0 2 3 1 2 0]\n",
      " [3 2 3 1 0 1 3]\n",
      " [2 1 3 3 2 0 3]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 13745733.418057596\n",
      "action [[0 2 1 1 2 2 3]\n",
      " [1 0 0 1 2 3 2]\n",
      " [3 0 1 2 0 3 3]\n",
      " [0 1 3 2 0 0 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 14967679.443319777\n",
      "action [[0 3 0 1 0 3 0]\n",
      " [3 0 1 1 0 2 2]\n",
      " [1 3 3 2 1 0 3]\n",
      " [2 1 0 3 3 0 3]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 14401421.43141438\n",
      "action [[2 0 2 1 0 2 0]\n",
      " [1 3 0 3 2 3 1]\n",
      " [0 0 0 2 0 1 3]\n",
      " [2 0 2 2 1 1 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 13725825.418977614\n",
      "action [[1 2 0 1 3 3 2]\n",
      " [3 0 1 1 1 0 0]\n",
      " [2 2 2 3 2 2 0]\n",
      " [1 1 0 1 0 2 1]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 15296169.423340023\n",
      "action [[1 3 2 0 0 1 0]\n",
      " [2 3 2 0 0 1 2]\n",
      " [3 0 2 0 1 0 3]\n",
      " [0 2 3 2 1 3 0]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 14884507.430095859\n",
      "action [[2 0 1 1 2 2 2]\n",
      " [1 0 0 3 0 0 1]\n",
      " [2 3 3 0 0 1 2]\n",
      " [2 2 2 3 0 0 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 16004269.437738765\n",
      "action [[1 2 0 2 0 2 3]\n",
      " [0 1 0 3 2 0 0]\n",
      " [2 0 3 2 2 2 2]\n",
      " [2 2 1 1 3 2 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 17280015.447428126\n",
      "action [[1 1 2 0 0 2 3]\n",
      " [2 1 3 1 2 1 0]\n",
      " [3 2 2 3 2 0 0]\n",
      " [1 3 1 0 0 2 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 16937863.441680882\n",
      "action [[2 1 1 0 0 1 3]\n",
      " [3 2 1 3 2 3 0]\n",
      " [1 1 2 2 0 3 0]\n",
      " [0 2 1 1 0 2 1]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 17582301.458830364\n",
      "action [[2 3 0 2 2 1 3]\n",
      " [3 2 2 1 3 1 0]\n",
      " [2 1 2 1 1 3 3]\n",
      " [1 0 2 3 2 3 0]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 18117859.471830156\n",
      "action [[3 1 2 3 2 0 0]\n",
      " [1 0 0 3 0 2 3]\n",
      " [2 2 2 1 0 2 1]\n",
      " [1 2 0 2 1 0 3]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 19064475.473136485\n",
      "action [[2 0 0 1 0 0 2]\n",
      " [1 1 0 1 0 1 2]\n",
      " [0 3 2 2 3 2 2]\n",
      " [3 2 1 3 3 1 2]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 19660483.476064198\n",
      "action [[1 0 1 0 0 1 3]\n",
      " [0 2 2 3 0 2 3]\n",
      " [3 3 3 3 0 0 0]\n",
      " [0 1 1 1 0 1 0]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 20897861.50660328\n",
      "action [[3 0 2 0 3 0 0]\n",
      " [2 0 0 2 2 1 1]\n",
      " [3 3 1 3 0 2 0]\n",
      " [1 1 2 0 1 2 1]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 23007339.51808595\n",
      "action [[1 1 3 3 1 3 0]\n",
      " [0 3 0 2 0 3 3]\n",
      " [1 3 0 0 3 1 0]\n",
      " [2 3 0 2 3 0 0]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 25366385.533439197\n",
      "action [[3 2 2 3 0 1 1]\n",
      " [1 1 2 0 2 3 0]\n",
      " [3 2 2 1 2 0 0]\n",
      " [0 3 1 1 2 3 3]]\n",
      "abc\n",
      "def\n",
      "ghi\n",
      "reward 26940935.542251125\n",
      "action [[2 0 3 2 0 0 0]\n",
      " [1 2 2 0 3 3 1]\n",
      " [0 0 0 1 3 2 3]\n",
      " [3 0 1 1 0 3 2]]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m random_action \u001b[38;5;241m=\u001b[39m envv\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39msample()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m\"\u001b[39m,random_action)\n\u001b[0;32m---> 14\u001b[0m obs, reward, done, trunc, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m#print(\"obs\", obs)\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreward\u001b[39m\u001b[38;5;124m'\u001b[39m,reward)\n",
      "Cell \u001b[0;32mIn[11], line 150\u001b[0m, in \u001b[0;36mCustomEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    146\u001b[0m U \u001b[38;5;241m=\u001b[39m evaluation\u001b[38;5;241m.\u001b[39mget_utilization(D, Zf)\n\u001b[1;32m    148\u001b[0m L \u001b[38;5;241m=\u001b[39m evaluation\u001b[38;5;241m.\u001b[39mget_normalized_lifespan(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfleet)\n\u001b[0;32m--> 150\u001b[0m P \u001b[38;5;241m=\u001b[39m \u001b[43mevaluation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_profit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mD\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[43m               \u001b[49m\u001b[43mZf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m    152\u001b[0m \u001b[43m               \u001b[49m\u001b[43mselling_prices\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m               \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfleet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m o \u001b[38;5;241m=\u001b[39m U \u001b[38;5;241m*\u001b[39m L \u001b[38;5;241m*\u001b[39m P\n\u001b[1;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mOBJECTIVE \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m o\n",
      "File \u001b[0;32m~/projects/huawei/Hackathon-Huawei/rl_agent/evaluation.py:252\u001b[0m, in \u001b[0;36mget_profit\u001b[0;34m(D, Z, selling_prices, fleet)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_profit\u001b[39m(D, Z, selling_prices, fleet):\n\u001b[1;32m    250\u001b[0m     \u001b[38;5;66;03m# CALCULATE OBJECTIVE P = PROFIT\u001b[39;00m\n\u001b[1;32m    251\u001b[0m     R \u001b[38;5;241m=\u001b[39m get_revenue(D, Z, selling_prices)\n\u001b[0;32m--> 252\u001b[0m     C \u001b[38;5;241m=\u001b[39m \u001b[43mget_cost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfleet\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    253\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m R \u001b[38;5;241m-\u001b[39m C\n",
      "File \u001b[0;32m~/projects/huawei/Hackathon-Huawei/rl_agent/evaluation.py:272\u001b[0m, in \u001b[0;36mget_cost\u001b[0;34m(fleet)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_cost\u001b[39m(fleet):\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;66;03m# CALCULATE THE COST\u001b[39;00m\n\u001b[0;32m--> 272\u001b[0m     fleet[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcost\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mfleet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcalculate_server_cost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fleet[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcost\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\n",
      "File \u001b[0;32m~/projects/huawei/Hackathon-Huawei/.venv/lib/python3.9/site-packages/pandas/core/frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[0;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[1;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[1;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[1;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m  10373\u001b[0m )\n\u001b[0;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/projects/huawei/Hackathon-Huawei/.venv/lib/python3.9/site-packages/pandas/core/apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[0;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/huawei/Hackathon-Huawei/.venv/lib/python3.9/site-packages/pandas/core/apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[0;32m~/projects/huawei/Hackathon-Huawei/.venv/lib/python3.9/site-packages/pandas/core/apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[0;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[1;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/projects/huawei/Hackathon-Huawei/rl_agent/evaluation.py:278\u001b[0m, in \u001b[0;36mcalculate_server_cost\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_server_cost\u001b[39m(row):\n\u001b[1;32m    277\u001b[0m     c \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 278\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpurchase_price\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    279\u001b[0m     b \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maverage_maintenance_fee\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    280\u001b[0m     x \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlifespan\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/projects/huawei/Hackathon-Huawei/.venv/lib/python3.9/site-packages/pandas/core/series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[1;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[0;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[1;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[1;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[0;32m~/projects/huawei/Hackathon-Huawei/.venv/lib/python3.9/site-packages/pandas/core/series.py:1240\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(label)\n\u001b[1;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_values\u001b[49m[loc]\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, MultiIndex):\n\u001b[1;32m   1243\u001b[0m     mi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\n",
      "File \u001b[0;32m~/projects/huawei/Hackathon-Huawei/.venv/lib/python3.9/site-packages/pandas/core/series.py:863\u001b[0m, in \u001b[0;36mSeries._values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    832\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_values\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    833\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    834\u001b[0m \u001b[38;5;124;03m    Return the internal repr of this data (defined by Block.interval_values).\u001b[39;00m\n\u001b[1;32m    835\u001b[0m \u001b[38;5;124;03m    This are the values as stored in the Block (ndarray or ExtensionArray\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    861\u001b[0m \n\u001b[1;32m    862\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minternal_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/huawei/Hackathon-Huawei/.venv/lib/python3.9/site-packages/pandas/core/internals/managers.py:2006\u001b[0m, in \u001b[0;36mSingleBlockManager.internal_values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minternal_values\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The array that Series._values returns\"\"\"\u001b[39;00m\n\u001b[0;32m-> 2006\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_block\u001b[49m\u001b[38;5;241m.\u001b[39mvalues\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "envv = CustomEnv()\n",
    "#check environmento\n",
    "check_env(envv)\n",
    "\n",
    "#extra checks, unocomment to run\n",
    "episodes = 4\n",
    "\n",
    "for episode in range(episodes):\n",
    "    done = False\n",
    "    obs = envv.reset()\n",
    "    while not done:\n",
    "        random_action = envv.action_space.sample()\n",
    "        print(\"action\",random_action)\n",
    "        obs, reward, done, trunc, info = env.step(random_action)\n",
    "        #print(\"obs\", obs)\n",
    "        print('reward',reward)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Logging to logs/V2/1724927987/PPO_0\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not numpy.float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[13], line 27\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m#adjust the range below to adjust timesteps it runs for (calc stepcount as max range val * timesteps)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#saves model every TIMESTEPS number of steps\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m50\u001b[39m):\n\u001b[0;32m---> 27\u001b[0m     \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTIMESTEPS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPPO\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     model\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTIMESTEPS\u001b[38;5;241m*\u001b[39mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/projects/huawei/Hackathon-Huawei/.venv/lib/python3.9/site-packages/stable_baselines3/a2c/a2c.py:201\u001b[0m, in \u001b[0;36mA2C.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    193\u001b[0m     \u001b[38;5;28mself\u001b[39m: SelfA2C,\n\u001b[1;32m    194\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    199\u001b[0m     progress_bar: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    200\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m SelfA2C:\n\u001b[0;32m--> 201\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    203\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    204\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    205\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/huawei/Hackathon-Huawei/.venv/lib/python3.9/site-packages/stable_baselines3/common/on_policy_algorithm.py:300\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, tb_log_name, reset_num_timesteps, progress_bar)\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 300\u001b[0m     continue_training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrollout_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_rollout_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_steps\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    302\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m continue_training:\n\u001b[1;32m    303\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/huawei/Hackathon-Huawei/.venv/lib/python3.9/site-packages/stable_baselines3/common/on_policy_algorithm.py:195\u001b[0m, in \u001b[0;36mOnPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, rollout_buffer, n_rollout_steps)\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;66;03m# Otherwise, clip the actions to avoid out of bound error\u001b[39;00m\n\u001b[1;32m    192\u001b[0m         \u001b[38;5;66;03m# as we are sampling from an unbounded Gaussian distribution\u001b[39;00m\n\u001b[1;32m    193\u001b[0m         clipped_actions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mclip(actions, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mlow, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39mhigh)\n\u001b[0;32m--> 195\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclipped_actions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mnum_envs\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# Give access to local variables\u001b[39;00m\n",
      "File \u001b[0;32m~/projects/huawei/Hackathon-Huawei/.venv/lib/python3.9/site-packages/stable_baselines3/common/vec_env/base_vec_env.py:206\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[1;32m    201\u001b[0m \n\u001b[1;32m    202\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/projects/huawei/Hackathon-Huawei/.venv/lib/python3.9/site-packages/stable_baselines3/common/vec_env/dummy_vec_env.py:58\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[0;32m---> 58\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[1;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx] \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "File \u001b[0;32m~/projects/huawei/Hackathon-Huawei/.venv/lib/python3.9/site-packages/stable_baselines3/common/monitor.py:94\u001b[0m, in \u001b[0;36mMonitor.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mneeds_reset:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to step environment that needs reset\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 94\u001b[0m observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrewards\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(reward))\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated:\n",
      "Cell \u001b[0;32mIn[11], line 130\u001b[0m, in \u001b[0;36mCustomEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;124;03mafter agent move, do it, calc the new observation state\u001b[39;00m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;124;03mand the reward from that move it made, if \"end\" of game set self.done to True\u001b[39;00m\n\u001b[1;32m    126\u001b[0m \n\u001b[1;32m    127\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    128\u001b[0m selling_prices \u001b[38;5;241m=\u001b[39m evaluation\u001b[38;5;241m.\u001b[39mchange_selling_prices_format(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mselling_prices)\n\u001b[0;32m--> 130\u001b[0m actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactionspace\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_actionspace_to_actionV2\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m actions:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m(i[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbuy\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m~/projects/huawei/Hackathon-Huawei/rl_agent/action.py:105\u001b[0m, in \u001b[0;36mActionSpace.convert_actionspace_to_actionV2\u001b[0;34m(self, agent_action)\u001b[0m\n\u001b[1;32m    103\u001b[0m         action_number \u001b[38;5;241m=\u001b[39m agent_action[datacenter,server_gen]\n\u001b[1;32m    104\u001b[0m         server_gen \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mserver_generations[server_gen]\n\u001b[0;32m--> 105\u001b[0m         action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moperation_types\u001b[49m\u001b[43m[\u001b[49m\u001b[43maction_number\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    106\u001b[0m         actions\u001b[38;5;241m.\u001b[39mappend([action, server_gen, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, datacenter_id])\n\u001b[1;32m    107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m actions\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not numpy.float64"
     ]
    }
   ],
   "source": [
    "train()\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
